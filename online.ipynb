{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(980970, 4)\n",
      "(188885672, 5)\n"
     ]
    }
   ],
   "source": [
    "# Загружаем данные\n",
    "import pandas as pd\n",
    "\n",
    "from utils import load_parquet_from_s3\n",
    "\n",
    "items = pd.read_parquet(load_parquet_from_s3(\"recsys/data/items.parquet\"))\n",
    "print(items.shape)\n",
    "\n",
    "events = pd.read_parquet(load_parquet_from_s3(\"recsys/data/events.parquet\"))\n",
    "print(events.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178811394, 5) (10074278, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_100527/3072731248.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  events_train[\"user_id_enc\"] = user_encoder.transform(events_train[\"user_id\"])\n",
      "/tmp/ipykernel_100527/3072731248.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  events_test[\"user_id_enc\"] = user_encoder.transform(events_test[\"user_id\"])\n",
      "/tmp/ipykernel_100527/3072731248.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  events_train[\"item_id_enc\"] = item_encoder.transform(events_train[\"item_id\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "980969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_100527/3072731248.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  events_test[\"item_id_enc\"] = item_encoder.transform(events_test[\"item_id\"])\n"
     ]
    }
   ],
   "source": [
    "# Разделим данные\n",
    "import sklearn.preprocessing\n",
    "\n",
    "train_test_global_time_split_date = pd.to_datetime(\"2022-12-16\")\n",
    "train_test_global_time_split_idx = events[\"started_at\"] < train_test_global_time_split_date\n",
    "events_train = events[train_test_global_time_split_idx]\n",
    "events_test = events[~train_test_global_time_split_idx]\n",
    "print(events_train.shape, events_test.shape)\n",
    "\n",
    "# перекодируем идентификаторы пользователей: \n",
    "# из имеющихся в последовательность 0, 1, 2, ...\n",
    "user_encoder = sklearn.preprocessing.LabelEncoder()\n",
    "user_encoder.fit(events[\"user_id\"])\n",
    "events_train[\"user_id_enc\"] = user_encoder.transform(events_train[\"user_id\"])\n",
    "events_test[\"user_id_enc\"] = user_encoder.transform(events_test[\"user_id\"])\n",
    "\n",
    "# перекодируем идентификаторы объектов: \n",
    "item_encoder = sklearn.preprocessing.LabelEncoder()\n",
    "item_encoder.fit(items[\"item_id\"])\n",
    "items[\"item_id_enc\"] = item_encoder.transform(items[\"item_id\"])\n",
    "events_train[\"item_id_enc\"] = item_encoder.transform(events_train[\"item_id\"])\n",
    "events_test[\"item_id_enc\"] = item_encoder.transform(events_test[\"item_id\"])\n",
    "print(events_train['item_id_enc'].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "979546\n",
      "475751\n",
      "434.0149360205978\n"
     ]
    }
   ],
   "source": [
    "# Вычислим размер матрицы\n",
    "x = events_train['item_id_enc'].nunique()\n",
    "print(x)\n",
    "y = events_train['user_id_enc'].nunique()\n",
    "print(y)\n",
    "r = ((x * y) / 1024 ** 3)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Матрица создана!\n"
     ]
    }
   ],
   "source": [
    "# Создадим матрицу\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "user_item_matrix_train = scipy.sparse.csr_matrix((\n",
    "    np.ones(len(events_train), dtype=np.int8),  # Значения: 1 для каждой пары\n",
    "    (events_train['user_id_enc'], events_train['item_id_enc'])),\n",
    "    dtype=np.int8)\n",
    "print('Матрица создана!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/mle_projects/mle-recsys-project-start/env_recsys_start/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/mle-user/mle_projects/mle-recsys-project-start/env_recsys_start/lib/python3.10/site-packages/implicit/cpu/als.py:95: RuntimeWarning: OpenBLAS is configured to use 4 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
      "  check_blas_config()\n",
      "100%|██████████| 50/50 [37:29<00:00, 45.00s/it]\n"
     ]
    }
   ],
   "source": [
    "# Создадим и натренируем модель\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "\n",
    "als_model = AlternatingLeastSquares(factors=50, iterations=50, regularization=0.05, random_state=0)\n",
    "als_model.fit(user_item_matrix_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Готово!\n"
     ]
    }
   ],
   "source": [
    "# Получим набор похожих объектов в similar_items\n",
    "\n",
    "# получим энкодированные идентификаторы всех объектов, известных нам из events_train\n",
    "train_item_ids_enc = events_train['item_id_enc'].unique()\n",
    "\n",
    "max_similar_items = 10\n",
    "\n",
    "# получаем списки похожих объектов, используя ранее полученную ALS-модель\n",
    "# метод similar_items возвращает и сам объект, как наиболее похожий\n",
    "# этот объект мы позже отфильтруем, но сейчас запросим на 1 больше\n",
    "similar_items = als_model.similar_items(train_item_ids_enc, N=max_similar_items+1)\n",
    "\n",
    "# преобразуем полученные списки в табличный формат\n",
    "sim_item_item_ids_enc = similar_items[0]\n",
    "sim_item_scores = similar_items[1]\n",
    "\n",
    "similar_items = pd.DataFrame({\n",
    "    \"item_id_enc\": train_item_ids_enc,\n",
    "    \"sim_item_id_enc\": sim_item_item_ids_enc.tolist(), \n",
    "    \"score\": sim_item_scores.tolist()})\n",
    "similar_items = similar_items.explode([\"sim_item_id_enc\", \"score\"], ignore_index=True)\n",
    "\n",
    "# приводим типы данных\n",
    "similar_items[\"sim_item_id_enc\"] = similar_items[\"sim_item_id_enc\"].astype(\"int\")\n",
    "similar_items[\"score\"] = similar_items[\"score\"].astype(\"float\")\n",
    "\n",
    "# получаем изначальные идентификаторы\n",
    "similar_items[\"item_id_1\"] = item_encoder.inverse_transform(similar_items[\"item_id_enc\"])\n",
    "similar_items[\"item_id_2\"] = item_encoder.inverse_transform(similar_items[\"sim_item_id_enc\"])\n",
    "similar_items = similar_items.drop(columns=[\"item_id_enc\", \"sim_item_id_enc\"])\n",
    "\n",
    "# убираем пары с одинаковыми объектами\n",
    "similar_items = similar_items.query(\"item_id_1 != item_id_2\")\n",
    "print('Готово!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл успешно сохранен на S3 по пути: recsys/recommendations/similar_items.parquet\n"
     ]
    }
   ],
   "source": [
    "# Сохраним набор похожих объектов\n",
    "import os\n",
    "import io\n",
    "import boto3\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "S3_ENDPOINT_URL = \"https://storage.yandexcloud.net\"\n",
    "AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "S3_BUCKET_NAME = os.getenv(\"S3_BUCKET_NAME\")\n",
    "\n",
    "# Путь к файлу на S3\n",
    "s3_key = \"recsys/recommendations/similar_items.parquet\"\n",
    "\n",
    "s3_client = boto3.client(\"s3\",\n",
    "    endpoint_url=S3_ENDPOINT_URL,\n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    ")\n",
    "\n",
    "# Сохраняем\n",
    "buffer = io.BytesIO()\n",
    "similar_items.to_parquet(buffer, index=False)\n",
    "buffer.seek(0)\n",
    "\n",
    "# Загружаем файл на S3\n",
    "s3_client.put_object(\n",
    "    Bucket=S3_BUCKET_NAME,\n",
    "    Key=s3_key,\n",
    "    Body=buffer\n",
    ")\n",
    "\n",
    "print(f\"Файл успешно сохранен на S3 по пути: {s3_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9796212, 3)\n",
      "      score  item_id_1  item_id_2\n",
      "0  0.978334        966   37408173\n",
      "1  0.974815        966   37408181\n"
     ]
    }
   ],
   "source": [
    "# Загружаем данные\n",
    "import pandas as pd\n",
    "\n",
    "from utils import load_parquet_from_s3\n",
    "\n",
    "similar_items = pd.read_parquet(load_parquet_from_s3(\"recsys/recommendations/similar_items.parquet\"))\n",
    "print(similar_items.shape)\n",
    "print(similar_items.head(2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4 13 14 16 19 22 23 24 25 26]\n"
     ]
    }
   ],
   "source": [
    "events['user_id'].unique()\n",
    "print(events['user_id'].unique()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         score  item_id_1  item_id_2\n",
      "3770  0.882784      53404      96089\n",
      "3771  0.877298      53404      37384\n",
      "3772  0.873760      53404     178529\n",
      "3773  0.873183      53404    6705392\n",
      "3774  0.867275      53404     148345\n",
      "3775  0.831046      53404      48951\n",
      "3776  0.823033      53404      53412\n",
      "3777  0.811312      53404      36246\n",
      "3778  0.778754      53404     178495\n",
      "3779  0.777983      53404     694683\n"
     ]
    }
   ],
   "source": [
    "# Укажите идентификатор объекта, наиболее похожего на объект\n",
    "filtered_items = similar_items[similar_items['item_id_1'] == 53404]\n",
    "print(filtered_items)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_recsys_start",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
